{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82270c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1º Etapa\n",
    "import pandas as pd \n",
    "treino = pd.read_csv('treino.csv') # Lendo os arquivos\n",
    "teste = pd.read_csv('teste.csv') # Lendo os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fe351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alterando os nomes das colunas “temratura-50m” e “velocidde-vento-25m” para “temperatura-50m” e “velocidade-vento-25m”;\n",
    "treino.rename(columns={'temratura-50m':'temperatura-50m','velocidde-vento-25m': 'velocidade-vento-25m'}, inplace=True)\n",
    "teste.rename(columns={'temratura-50m':'temperatura-50m','velocidde-vento-25m': 'velocidade-vento-25m'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5da078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exiba os 5 primeiros elementos do dataset de treino e de teste;\n",
    "treino.head() \n",
    "teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exiba a quantidade total de elementos nas tabelas \n",
    "#e a média dos valores da coluna velocidade-vento-50m;\n",
    "treino.count().sum() # retorna o total de elementos da tabela\n",
    "teste.count().sum() # retorna o total de elementos da tabela\n",
    "treino['velocidade-vento-50m'].mean()\n",
    "teste['velocidade-vento-50m'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114eb815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exiba qual Data apresentou o maior valor de velocidade-vento-50m;\n",
    "treino['velocidade-vento-50m'].max()\n",
    "teste['velocidade-vento-50m'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gráficos interessante para o problema em questão e justifique a escolha deles\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(treino[[\"velocidade-vento-50m\"]], label='Velocidade-vento-50m')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(treino[[\"velocidade-vento-50m\"]], diag_kind=\"kde\")\n",
    "train_stats = treino[[\"velocidade-vento-50m\"]].describe()\n",
    "train_stats.pop(\"velocidade-vento-50m\")\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d76b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2º Etapa\n",
    "#Tratamento de dados para lidar com os dados faltantes;\n",
    "valores_ausentes = treino.isnull()\n",
    "medias = treino.mean() #média da coluna\n",
    "treino.fillna(medias, inplace=True)\n",
    "treino.isna().sum()\n",
    "\n",
    "valores_ausentes = teste.isnull()\n",
    "medias = teste.mean() #média da coluna\n",
    "teste.fillna(medias, inplace=True)\n",
    "teste.isna().sum() #Verificando se existe valores nulos ou contém alguns valores não conhecidos (unknown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a94074",
   "metadata": {},
   "outputs": [],
   "source": [
    "treino['data-hora'] = pd.to_datetime(treino['data-hora'])\n",
    "treino.set_index('data-hora', inplace=True)\n",
    "\n",
    "teste['data-hora'] = pd.to_datetime(teste['data-hora'])\n",
    "teste.set_index('data-hora', inplace=True)\n",
    "\n",
    "vel = [\"velocidade-vento-50m\"]\n",
    "treino = treino.loc[:, vel]\n",
    "treino.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalone os dados de entrada para que fiquem dentro da faixa de valores entre 0 e 1;\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scl = MinMaxScaler(feature_range= (0,1))\n",
    "treino = scl.fit_transform(treino)\n",
    "teste = scl.fit_transform(teste)\n",
    "arrayTr = treino\n",
    "arrayTe = teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f40993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divida os dados de treinamento em X_train e y_train\n",
    "look_back = 20 #dias anteriores\n",
    "forward_hours = 3 #prever o que acontecerá com o valor n horas(3 próximas horas)\n",
    "num_periods = 10 # períodos (num_periods) para testar o modelo\n",
    "\n",
    "#A cada período, o modelo irá prever os próximos n dias.\n",
    "#O resto será utilizado para o treinamento (Treino e Validação).\n",
    "\n",
    "div = len(arrayTr) - num_periods*forward_hours\n",
    "\n",
    "array_test = arrayTe[:]\n",
    "array_train = arrayTr[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914abed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar modelo\n",
    "import pickle\n",
    "# salvar o array no arquivo norm.pkl\n",
    "pickle.dump(scl, open('Escalonador.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ead771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados na entrada X e na saída Y, dividindo em 'n' dias anteriores como entrada X \n",
    "#e 'm' próximos dias como Y\n",
    "import numpy as np\n",
    "def processData(data, look_back, forward_hours,jump=1):\n",
    "    X,Y = [],[]\n",
    "    for i in range(0,len(data) -look_back -forward_hours +1, jump):\n",
    "        X.append(data[i:(i+look_back)])\n",
    "        Y.append(data[(i+look_back):(i+look_back+forward_hours)])\n",
    "    return np.array(X),np.array(Y)\n",
    "\n",
    "\n",
    "#Divida os dados de teste em X_test e y_test\n",
    "\n",
    "\n",
    "X_test,y_test = processData(array_test,look_back,forward_hours,forward_hours)\n",
    "y_test = np.array([list(a.ravel()) for a in y_test])\n",
    "\n",
    "X,y = processData(array_train,look_back,forward_hours)\n",
    "y = np.array([list(a.ravel()) for a in y])\n",
    "\n",
    "#Separe uma parte dos dados de X_train e y_train para validação (X_val e y_val);\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e906661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3º Etapa\n",
    "#Desenvolva um modelo que aprenda a predizer a velocidade-vento-50m\n",
    "# das 3 próximas horas a partir dos dados de treinamento\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "NUM_NEURONS_FirstLayer = 25\n",
    "NUM_NEURONS_SecondLayer = 15\n",
    "EPOCHS = 25\n",
    "\n",
    "#Build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(NUM_NEURONS_FirstLayer,input_shape=(look_back,1), return_sequences=True))\n",
    "model.add(LSTM(NUM_NEURONS_SecondLayer,input_shape=(NUM_NEURONS_FirstLayer,1)))\n",
    "model.add(Dense(forward_hours))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs=EPOCHS,validation_data=(X_validate,y_validate),shuffle=True,batch_size=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresente o gráfico de loss de treinamento e validação do modelo. \n",
    "#Mostre que o modelo não apresenta over/underfitting;\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe14b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresente gráficos e tabelas relacionados ao desempenho do modelo desenvolvido, explicando os resultados\n",
    "\n",
    "Xt = model.predict(X_test)\n",
    "#prever os dados de Teste para o resultado\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(0, len(Xt)):\n",
    "    plt.plot([x + i * forward_hours for x in range(len(Xt[i]))], scl.inverse_transform(Xt[i].reshape(-1, 1)), color='r')\n",
    "\n",
    "plt.plot(0, scl.inverse_transform(Xt[i].reshape(-1, 1))[0], color='r', label='Prediction')  # only to place the label\n",
    "\n",
    "plt.plot(scl.inverse_transform(y_test.reshape(-1, 1)), label='Target')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "division = len(array) - num_periods*forward_hours\n",
    "\n",
    "leftover = division%forward_hours+1\n",
    "\n",
    "array_test = array[division-look_back:]\n",
    "array_train = array[leftover:division]\n",
    "\n",
    "Xtrain,ytrain = processData(array_train,look_back,forward_hours,forward_hours)\n",
    "Xtest,ytest = processData(array_test,look_back,forward_hours,forward_hours)\n",
    "\n",
    "\n",
    "Xtrain = model.predict(Xtrain)\n",
    "Xtrain = Xtrain.ravel()\n",
    "\n",
    "Xtest = model.predict(Xtest)\n",
    "Xtest = Xtest.ravel()\n",
    "\n",
    "y = np.concatenate((ytrain, ytest), axis=0)\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "\n",
    "# Data in Train/Validation\n",
    "plt.plot([x for x in range(look_back+leftover, len(Xtrain)+look_back+leftover)], scl.inverse_transform(Xtrain.reshape(-1,1)), color='r', label='Train')\n",
    "# Data in Test\n",
    "plt.plot([x for x in range(look_back +leftover+ len(Xtrain), len(Xtrain)+len(Xtest)+look_back+leftover)], scl.inverse_transform(Xtest.reshape(-1,1)), color='y', label='Test')\n",
    "\n",
    "#Data used\n",
    "#plt.plot([x for x in range(look_back+leftover, look_back+leftover+len(Xtrain)+len(Xtest))], scl.inverse_transform(y.reshape(-1,1)), color='b', label='Target')\n",
    "\n",
    "#Initial data. It should overlap the data used\n",
    "plt.plot(scl.inverse_transform(array), color='g', label='Esperado')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avalie quantitativamente o desempenho final do modelo desenvolvido a partir dos dados de teste, \n",
    "# utilizando as métricas Mean Squared Error (MSE), Mean Absolute Error (MAE), coeficiente de correlação Pearson r e o coeficiente de determinação R²;\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
